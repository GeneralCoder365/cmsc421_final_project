{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csvs_from_dir(directory):\n",
    "    datasets_dir = os.path.join(directory, 'environment', 'datasets')\n",
    "    try:\n",
    "        csv_files = [os.path.join(datasets_dir, file) for file in os.listdir(datasets_dir) if file.endswith('.csv')]\n",
    "        stock_names = [os.path.basename(file).replace('.csv', '') for file in csv_files]\n",
    "        return csv_files, stock_names\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The directory {datasets_dir} does not exist.\")\n",
    "        return [], []\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def black_scholes(S, K, T, r, sigma, option_type='call'):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return (S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)) if option_type == 'call' else (K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1))\n",
    "\n",
    "def calculate_arbitrage(df, r, sigma, T, volume, results_dir, model_name):\n",
    "    # if model_name is 'lstm', then no profit should be gotten in the first 10 days since that is part of the data used to make the first prediction\n",
    "    # but the df should still be the same length as the original df\n",
    "    if model_name == 'lstm':\n",
    "        df = df[10:]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        call_price_predicted = black_scholes(row[model_name], row['actual'], T, r, sigma, 'call')\n",
    "        put_price_predicted = black_scholes(row[model_name], row['actual'], T, r, sigma, 'put')\n",
    "        call_price_actual = black_scholes(row['actual'], row['actual'], T, r, sigma, 'call')\n",
    "        put_price_actual = black_scholes(row['actual'], row['actual'], T, r, sigma, 'put')\n",
    "        arbitrage_type, gain = identify_arbitrage(call_price_predicted, put_price_predicted, call_price_actual, put_price_actual, volume)\n",
    "        results.append({'Month': index.strftime('%Y-%m'), 'Arbitrage Type': arbitrage_type, 'Gain': gain})\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # if model_name is 'lstm' then first 10 days with 0 value should be added to the results_df\n",
    "    if model_name == 'lstm':\n",
    "        results_df = pd.concat([pd.DataFrame([{'Month': index.strftime('%Y-%m'), 'Arbitrage Type': 'No Arbitrage', 'Gain': 0} for index, row in df[:10].iterrows()]), results_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Save results to a csv file\n",
    "    results_df.to_csv(os.path.join(results_dir, model_name+'_arbitrage.csv'), index=False)\n",
    "    return results_df\n",
    "\n",
    "def identify_arbitrage(call_pred, put_pred, call_act, put_act, volume):\n",
    "    if call_act > call_pred:\n",
    "        return 'Buy Call', (call_act - call_pred) * volume\n",
    "    elif put_act > put_pred:\n",
    "        return 'Buy Put', (put_act - put_pred) * volume\n",
    "    return 'No Arbitrage', 0\n",
    "\n",
    "\n",
    "def json_serializer(obj):\n",
    "    if isinstance(obj, (np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "def update_statistics(arbitrage_df, results_dir, model_name):\n",
    "    stats = {\n",
    "        'mean_arbitrage_gain': arbitrage_df['Gain'].mean(),\n",
    "        'max_arbitrage_gain': arbitrage_df['Gain'].max(),\n",
    "        'total_arbitrage_gain': arbitrage_df['Gain'].sum(),\n",
    "        'total_opportunities': len(arbitrage_df),\n",
    "        'opportunities_with_gain': (arbitrage_df['Gain'] > 0).sum(),\n",
    "        'opportunities_with_loss': (arbitrage_df['Gain'] < 0).sum(),\n",
    "        'opportunities_with_no_arbitrage': (arbitrage_df['Arbitrage Type'] == 'No Arbitrage').sum()\n",
    "    }\n",
    "    \n",
    "    json_file_path = os.path.join(results_dir, 'profit_stats.json')\n",
    "    # if file exists, append to it, else create a new file\n",
    "    if os.path.exists(json_file_path):\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data[model_name] = stats\n",
    "        with open(json_file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4, default=json_serializer)\n",
    "    else:\n",
    "        with open(json_file_path, 'w') as file:\n",
    "            json.dump({model_name: stats}, file, indent=4, default=json_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed a\n",
      "Processed aapl\n",
      "Processed abc\n",
      "Processed abt\n",
      "Processed acn\n",
      "Processed adbe\n",
      "Processed adi\n",
      "Processed adm\n",
      "Processed adp\n",
      "Processed ads\n",
      "Processed adsk\n",
      "Processed aee\n",
      "Processed aep\n",
      "Processed aes\n",
      "Processed afl\n",
      "Processed agn\n",
      "Processed aig\n",
      "Processed aiv\n",
      "Processed amzn\n",
      "Processed jnj\n",
      "Processed jpm\n",
      "Processed ko\n",
      "Processed mmm\n",
      "Processed msft\n"
     ]
    }
   ],
   "source": [
    "def process_stocks(directory, r, sigma, T, volume, model_name):\n",
    "    datasets, stock_names = get_csvs_from_dir(directory)\n",
    "    stock_names = stock_names\n",
    "    for stock_name in stock_names:\n",
    "        results_dir = os.path.join(directory, 'agents', 'trained_models', stock_name)\n",
    "        predictions_dir = os.path.join(results_dir, 'predictions.csv')\n",
    "        df = load_data(predictions_dir)\n",
    "        arbitrage_df = calculate_arbitrage(df, r, sigma, T, volume, results_dir, model_name)\n",
    "        update_statistics(arbitrage_df, results_dir, model_name)\n",
    "        print(f\"Processed {stock_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    project_dir = os.path.dirname(os.getcwd())\n",
    "    model_name = 'multidqn' # 'arima', 'lstm', 'multidqn'\n",
    "    \n",
    "    # Parameters: risk-free rate, volatility, time to maturity, volume (to simulate large financial institution)\n",
    "    r, sigma, T, volume = 0.01, 0.2, 1/12, 1000000\n",
    "    process_stocks(project_dir, r, sigma, T, volume, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
